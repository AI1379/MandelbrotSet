To optimize the efficiency and precision of the Mandelbrot set generation, we introduce several optimizations.

\subsection{Parallelism}\label{subsec:parallelism}

As all pixels in the image are independent of each other, we can parallelize the computation of the Mandelbrot set.
We introduce parallelism based on the OpenMP and CUDA .

In CPU versions, we use OpenMP to parallelize the computation of layer functions on each pixel.
Thanks to the integrated OpenMP support in modern compilers, we can implement parallelism with minimal code as
follows:

\begin{lstlisting}[gobble=4, label={lst:openmp_parallel_for}]
    #pragma omp parallel for
\end{lstlisting}

In GPU versions, we use CUDA to accelerate the computation of layer functions.
We split the image into blocks and assign each block to a CUDA thread.
Then, we can compute the layer function for each pixel in parallel.
These code are in \href{https://github.com/AI1379/MandelbrotSet/blob/master/src/MandelbrotSetCuda.cu}
{\texttt{src/MandelbrotSetCuda.cu}} .

\subsection{Asynchronous pipeline}\label{subsec:asynchronous-pipeline}

In video generation, the asynchronous workflow is a bit more complex.
Thus, we introduce \texttt{P2300 - std::execution}\textsuperscript{\cite{P2300Proposal}}
to build the asynchronous pipeline.
The P2300 proposal provides a high-level abstraction for asynchronous execution, which is a candidate for standard
C++ asynchrony and likely to be included in the C++26.
An experimental implementation of it is available in GitHub repository
\texttt{NVIDIA/stdexec}\textsuperscript{\cite{stdexec}}.

As for the video generation, we design this asynchronous pipeline:

\vspace{0.5cm}

\begin{tikzpicture}[
    node distance=1.5cm,
    startstop/.style={
        rectangle,
        rounded corners,
        minimum width=2cm,
        minimum height=0.8cm,
        text centered,
        draw=black,
        fill=red!30
    },
    process/.style={
        rectangle,
        minimum width=2cm,
        minimum height=0.8cm,
        text centered,
        draw=black,
        fill=blue!30
    },
    decision/.style={
        diamond,
        aspect=2.5,
        minimum width=1cm,
        minimum height=1cm,
        text centered,
        draw=black,
        fill=green!30
    },
    arrow/.style={
        thick,
        ->,
        >=Stealth[round]
    }
]
    \node (start) [startstop] {Start};
    \node (coro) [process, below=1cm of start] {Start coroutine};
    \node (generate) [process, right=1cm of start] {Generate frame};
    \node (detect) [process, right=1cm of generate] {Detect boundary};
    \node (send) [process, right=1cm of detect] {Send frame};
    \node (stopsignal) [process, below=2cm of send] {Send stop signal};
    \node (zoom) [process, right=1cm of coro] {Zoom in};
    \node (wait) [process, right=1cm of zoom] {Wait for next frame};
    \node (waitsignal) [decision, below=1cm of wait] {Signal received?};
    \node (waitqueue) [process, below=1cm of waitsignal] {Wait for all queued works};
    \node (waitall) [process, below right=0.5cm and -2cm of waitqueue] {Wait for all works};
    \node (end) [startstop, below=0.5cm of waitall] {End};

    \draw [arrow] (start) -- (generate);
    \draw [arrow] (generate) -- (detect);
    \draw [arrow] (detect) -- (send);
    \draw [->] (send) -- node[midway] {Generating next frame} ++(0, 1) -| (generate);
    \draw [arrow] (start) -- (coro);
    \draw [arrow] (coro) -- (zoom);
    \draw [arrow] (zoom) -- (wait);
    \draw [<-, dashed] (wait) --node {Get key frame} (send);
    \draw [arrow] (wait) -- (waitsignal);
    \draw [->] (waitsignal) -- node[left] {Yes} (waitqueue);
    \draw [->] (waitsignal) -- node[above] {No} ++(-3, 0) -| (zoom);
    \draw [arrow] (send) -- (stopsignal);
    \draw [arrow] (waitqueue) |- (waitall);
    \draw [arrow] (stopsignal) |- (waitall);
    \draw [arrow] (waitall) -- (end);

\end{tikzpicture}

\vspace{0.5cm}

With the facilities provided by the P2300 proposal, we can build a high-performance asynchronous pipeline for video
generation.
These code are in \href{https://github.com/AI1379/MandelbrotSet/blob/master/src/VideoGenerator.h}
{\texttt{src/VideoGenerator.h}}.

\subsection{Precision optimization}\label{subsec:precision-optimization}

To optimize the precision of the Mandelbrot set, we introduce the \texttt{ExtendedDouble}
type to store floating-point numbers with extended precision.
It is implemented by combining an extra \texttt{int} to store the exponent and a \texttt{double}
to store the mantissa.
It is useful for high-precision computation, while its performance is comparable to the \texttt{double}
and much faster than \texttt{mpfr\_t}.
The implementation is in \href{https://github.com/AI1379/MandelbrotSet/blob/master/src/ExtendedDouble.cu}
{\texttt{src/ExtendedDouble.cu}}.